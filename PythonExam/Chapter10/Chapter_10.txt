第10章 网络爬虫和自动化

- The good news about computer is that they do what you tell them to
  do. The bad news is that they do what you tell them to do.  ———— Ted Nelson

- 学习目标
    1. 掌握网络爬虫的基本方法
    2. 运用requests库编写基本URL访问过程
    3. 运损beautifulsoup4库解析和处理HTML
    4. 掌握向搜索引擎自动提交关键词并获取返回结果的方法

- 随着网络的迅速发展，如何有效的提取并利用信息很大程度上决定了解决问题的效率。索索
  引擎作为辅助程序员检索信息的工具已经有些力不从心。为了更高效的获取指定信息需要定
  向抓取并分析网页资源，网络爬虫火爆了起来

10.1 问题概述
- 要点：Python语言实现网络爬虫的问题引入
- Python语言发展中有一个里程碑式的应用事件，即Google在搜索引擎后端采用Python
  进行链接处理和开发，这是该语言发展成熟的重要标志。
- Python语言的简洁性和脚本特点非常适合链接和网页处理，因此，在Python的计算生态
  中，与URL和网页处理相关的第三方库很多
- 万维网(www)的快速发展带来了大量获取和提交网络信息的需求，产生了网络爬虫等一系列
  应用。
    - Python语言提供了很多类似的函数库，包括：urllib, urllib2, urllib3,
      wget, scrapy, requests等
    - 对于爬取回来的网页内容，可以通过re(正则表达式)、beautifulsoup4等函数库
      来处理
- 网络爬虫应用一般分为两个步骤：
    1. 通过网络链接获取网页内容，可通过requests库
    2. 对获得的网页内容进行处理，可通过beautifulsoup4库
- 使用Python语言实现网络爬虫和信息提交是非常简单的事情，代码行数很少，也无须掌握
  网络通信等方面的知识，非常适合非专业读者使用。然而，肆意爬取网络数据并不是文明
  现象，通过程序自动提交内容争取竞争性资源也不公平。就像那些肆意的推销电话一样，无
  视接听者意愿，不仅令人讨厌也有可能引发法律纠纷
- 拓展：Robots排除协议
    - Robots Exclusion Protocol, 也被称为爬虫协议，它是网站管理者表达是否
      希望爬虫自动获取网络信息意愿的方法。
    - 管理者可以在网站根目录放置一个robots.txt文件，并在文件中列出哪些链接不允
      许爬虫爬取。一般搜索引擎的爬虫会首先捕获这个文件，并根据文件要求爬取网站内
      容。
    - 排除协议重点约定不希望爬虫获取的内容，如果没有该文件则表示网站内容可以被爬
      虫获得，然而，Robots协议不是命令和强制手段，只是国际互联网的一种通用道德
      规范。绝大部分成熟的搜索引擎爬虫会遵循这个协议，建议个人也能按照互联网规范
      要求合理使用爬虫技术
- 思考与练习
    - 10.1 请思考网络爬虫的可能应用
        - 可通过大量获取网页内容来为数据挖掘和机器学习提供训练数据

10.2 模块10：requests库的使用
- 要点：requests库是一个简洁且简单的处理HTTP请求的第三方库
- 10.2.1 requests库概述
    - requests库最大的优点是程序编写过程更接近正常URL访问过程
    - requests库建立在urllib3库的基础上
        - 类似这种在其他函数库之上再封装功能、提供更友好函数的方式在Python语言
          中十分常见。
        - 在Python生态圈里，任何人都有通过技术创新或体验创新发表意见和展示才华
          的机会
    - requests库支持非常丰富的链接访问功能，包括：
        - 国际域名和URL获取
        - HTTP长连接和连接缓存
        - HTTP会话和Cookie保持
        - 浏览器使用风格的SSL验证
        - 基本的摘要认证
        - 有效的键值对Cookie记录
        - 自动解压缩
        - 自动内容解码
        - 文件分块上传
        - HTTP(S)代理功能
        - 连接超时处理
        - 流数据下载
        - …
    - 更多介绍：http://docs.python-requests.org


10.3 模块11：beautifulsoup4库的使用


10.4 实例20：中国大学排名爬虫


10.5 实例21：搜索关键词自动提交


本章小结
